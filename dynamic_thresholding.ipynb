{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f3e2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "window_size = 1000\n",
    "half_window = window_size // 2  # Half window for sliding\n",
    "\n",
    "# These will hold the anomaly label (0/1) and tail‐probability for each index\n",
    "anomaly_labels = np.full(len(df), np.nan)\n",
    "tail_probs     = np.full(len(df), np.nan)\n",
    "\n",
    "def process_window(data_window: pd.Series, idx_range: range):\n",
    "    \"\"\"\n",
    "    Given a pandas Series `data_window` and the corresponding indices in the original DataFrame\n",
    "    (idx_range), fit a Generalized Pareto to the upper 5% of values in data_window, then\n",
    "    compute tail‐probabilities for every point in data_window. Assign label=1 when prob<0.5.\n",
    "    \"\"\"\n",
    "    if data_window.empty:\n",
    "        return\n",
    "\n",
    "    # Compute the 95th percentile threshold\n",
    "    threshold = np.percentile(data_window, 95)\n",
    "\n",
    "    # Extract peaks above threshold for GPD fitting\n",
    "    peaks = data_window[data_window > threshold]\n",
    "    if peaks.empty:\n",
    "        # If no peaks above threshold, skip assignment\n",
    "        return\n",
    "\n",
    "    # Fit GPD to the peaks\n",
    "    shape, loc, scale = stats.genpareto.fit(peaks)\n",
    "\n",
    "    # Compute tail‐probabilities for all points in the window\n",
    "    probs = 1.0 - stats.genpareto.cdf(data_window, c=shape, loc=loc, scale=scale)\n",
    "\n",
    "    # Label as anomaly if tail-prob < 0.5\n",
    "    labels = (probs < 0.5).astype(int)\n",
    "\n",
    "    # Assign back to the global arrays\n",
    "    for i, original_idx in enumerate(idx_range):\n",
    "        if 0 <= original_idx < len(anomaly_labels):\n",
    "            anomaly_labels[original_idx] = labels[i]\n",
    "            tail_probs[original_idx]     = probs[i]\n",
    "\n",
    "\n",
    "# Beginning segment: indices [0, half_window)\n",
    "start_idx = 0\n",
    "end_idx   = half_window\n",
    "chunk = df['loss'].iloc[start_idx:end_idx]\n",
    "process_window(chunk, range(start_idx, end_idx))\n",
    "\n",
    "# Ending segment: indices [len(df) - half_window, len(df))\n",
    "start_idx = len(df) - half_window\n",
    "end_idx   = len(df)\n",
    "chunk = df['loss'].iloc[start_idx:end_idx]\n",
    "process_window(chunk, range(start_idx, end_idx))\n",
    "\n",
    "\n",
    "# We slide in steps of half_window so that windows overlap by half.\n",
    "for start in range(0, len(df) - window_size + 1, half_window):\n",
    "    window_slice = df['loss'].iloc[start : start + window_size]\n",
    "    assign_range = range(start + half_window, start + window_size)\n",
    "    process_window(window_slice, assign_range)\n",
    "\n",
    "results_df = pd.DataFrame({\n",
    "    'label': anomaly_labels,\n",
    "    'prob':  tail_probs\n",
    "})\n",
    "\n",
    "results_df.to_csv('/home/anomaly.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
